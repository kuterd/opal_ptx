{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "512a3491-533e-4fee-aed5-00ec7fbafa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opal_ptx import CuModuleWrapper, kernel_transformer\n",
    "\n",
    "from torch.utils.cpp_extension import load\n",
    "import torch\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31f7ff35-34b4-4641-aae8-2f1dcb4b469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kernel_transformer.kernel()\n",
    "def simple_wmma_gemm(A_: \"u64\", B_: \"u64\", D_: \"u64\", m: \"u32\", n: \"u32\", k: \"u32\"):\n",
    "    A: u64\n",
    "    ptx.cvta.to._global.u64(A, A_)\n",
    "\n",
    "    B: u64\n",
    "    ptx.cvta.to._global.u64(B, B_)\n",
    "    \n",
    "    D: u64\n",
    "    ptx.cvta.to._global.u64(D, D_)\n",
    "    \n",
    "    x: u32 = u32(\"%ctaid.x\") * 16\n",
    "    y: u32 = u32(\"%ctaid.y\") * 16\n",
    "\n",
    "    a: b32(8)\n",
    "    b: b32(8)\n",
    "    d: b32(8)\n",
    "\n",
    "    for i in range(len(d)):\n",
    "        ptx.mov.b32(d[i], 0)\n",
    "    \n",
    "    KI: u32 = 0\n",
    "    while KI < k:\n",
    "        _A: u64 = A + (y * k + KI) * 2\n",
    "        _B: u64 = B + (KI * n + x) * 2\n",
    "        \n",
    "        ptx.wmma.load.a.sync.aligned._global.m16n16k16.row.f16({*a}, [_A], k)\n",
    "        ptx.wmma.load.b.sync.aligned._global.m16n16k16.row.f16({*b}, [_B], n)\n",
    "    \n",
    "        ptx.wmma.mma.sync.aligned.m16n16k16.row.row.f32.f32({*d}, {*a}, {*b}, {*d})\n",
    "        KI += 16\n",
    "\n",
    "    _D: u64 = D_ + (y * n + x) * 4\n",
    "    ptx.wmma.store.d.sync.aligned.m16n16k16._global.row.f32([_D], {*d}, m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "454261ce-748b-4649-a928-355f3c6caa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kernel_transformer.kernel()\n",
    "def simple_wmma_gemm_f16(A_: \"u64\", B_: \"u64\", D_: \"u64\", m: \"u32\", n: \"u32\", k: \"u32\"):\n",
    "    A: u64\n",
    "    ptx.cvta.to._global.u64(A, A_)\n",
    "\n",
    "    B: u64\n",
    "    ptx.cvta.to._global.u64(B, B_)\n",
    "    \n",
    "    D: u64\n",
    "    ptx.cvta.to._global.u64(D, D_)\n",
    "    \n",
    "    x: u32 = u32(\"%ctaid.x\") * 16\n",
    "    y: u32 = u32(\"%ctaid.y\") * 16\n",
    "\n",
    "    a: b32(8)\n",
    "    b: b32(8)\n",
    "    d: b32(4)\n",
    "\n",
    "    for i in range(len(d)):\n",
    "        ptx.mov.b32(d[i], 0)\n",
    "    \n",
    "    KI: u32 = 0\n",
    "    while KI < k:\n",
    "        _A: u64 = A + (y * k + KI) * 2\n",
    "        _B: u64 = B + (KI * n + x) * 2\n",
    "        \n",
    "        ptx.wmma.load.a.sync.aligned._global.m16n16k16.row.f16({*a}, [_A], k)\n",
    "        ptx.wmma.load.b.sync.aligned._global.m16n16k16.row.f16({*b}, [_B], n)\n",
    "    \n",
    "        ptx.wmma.mma.sync.aligned.m16n16k16.row.row.f16.f16({*d}, {*a}, {*b}, {*d})\n",
    "        KI += 16\n",
    "\n",
    "    _D: u64 = D_ + (y * n + x) * 2\n",
    "    ptx.wmma.store.d.sync.aligned.m16n16k16._global.row.f16([_D], {*d}, m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7f806e3d-d058-49f9-ae0b-1cfed8587e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum element difference tensor(2.5000, device='cuda:0', dtype=torch.float16)\n",
      "tensor([[501.0000, 400.0000, 498.0000,  ..., 496.0000, 516.0000, 407.7500],\n",
      "        [502.5000, 432.2500, 535.5000,  ..., 504.0000, 545.5000, 527.5000],\n",
      "        [518.5000, 452.0000, 511.2500,  ..., 520.5000, 558.0000, 465.5000],\n",
      "        ...,\n",
      "        [467.2500, 402.0000, 497.2500,  ..., 443.5000, 532.5000, 473.5000],\n",
      "        [525.0000, 482.2500, 564.5000,  ..., 520.5000, 527.0000, 469.5000],\n",
      "        [563.5000, 437.5000, 497.2500,  ..., 509.2500, 530.5000, 497.2500]],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "We fucked up\n"
     ]
    }
   ],
   "source": [
    "kernel_builder = kernel_transformer.KernelBuilder()\n",
    "simple_wmma_gemm_f16(kernel_builder)\n",
    "kernel_code = kernel_builder.generate()\n",
    "\n",
    "M = 512\n",
    "N = 512\n",
    "K = 512\n",
    "\n",
    "A = torch.randn((M, K), dtype=torch.float16, device=\"cuda\") + 1\n",
    "B = torch.randn((K, N), dtype=torch.float16, device=\"cuda\") + 1\n",
    "D = torch.zeros((M, N), dtype=torch.float16, device=\"cuda\")\n",
    "\n",
    "check = (A @ B)\n",
    "wrapper = CuModuleWrapper()\n",
    "wrapper.load_ptx_code(kernel_code)\n",
    "\n",
    "wrapper.launch_kernel(\"simple_wmma_gemm_f16\", ((M // 16), (N // 16), 1), (32, 1, 1), (A.data_ptr(), B.data_ptr(), D.data_ptr(), M, N, K), 0)\n",
    "print(\"Maximum element difference\", (D - check).abs().max())\n",
    "print(D) \n",
    "if torch.allclose(D, check, atol=0.124, rtol=0):\n",
    "    print(\"MATCH\")\n",
    "else:\n",
    "    print(\"We fucked up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b68c7679-5c51-425c-a45d-c6d5112d2ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum element difference tensor(0.0026, device='cuda:0')\n",
      "MATCH\n"
     ]
    }
   ],
   "source": [
    "kernel_builder = kernel_transformer.KernelBuilder()\n",
    "simple_wmma_gemm(kernel_builder)\n",
    "kernel_code = kernel_builder.generate()\n",
    "\n",
    "M = 512\n",
    "N = 512\n",
    "K = 512\n",
    "\n",
    "A = torch.randn((M, K), dtype=torch.float16, device=\"cuda\") + 1\n",
    "B = torch.randn((K, N), dtype=torch.float16, device=\"cuda\") + 1\n",
    "D = torch.zeros((M, N), dtype=torch.float32, device=\"cuda\")\n",
    "\n",
    "check = (A.to(torch.float32) @ B.to(torch.float32)).to(torch.float32)\n",
    "wrapper = CuModuleWrapper()\n",
    "wrapper.load_ptx_code(kernel_code)\n",
    "\n",
    "wrapper.launch_kernel(\"simple_wmma_gemm\", ((M // 16), (N // 16), 1), (32, 1, 1), (A.data_ptr(), B.data_ptr(), D.data_ptr(), M, N, K), 0)\n",
    "print(\"Maximum element difference\", (D - check).abs().max())\n",
    "\n",
    "if torch.allclose(D, check, atol=0.124, rtol=0):\n",
    "    print(\"MATCH\")\n",
    "else:\n",
    "    print(\"We fucked up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0689c4-93bb-44d7-b1a0-f112184d9b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d759ac4-3a99-4e12-aeb1-bee0597b6569",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
