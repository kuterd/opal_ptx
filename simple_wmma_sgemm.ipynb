{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "512a3491-533e-4fee-aed5-00ec7fbafa39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/normal/.local/lib/python3.12/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import transformer as kernel_transformer\n",
    "\n",
    "from torch.utils.cpp_extension import load\n",
    "import torch\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "trampoline = load(\n",
    "    \"extension\",\n",
    "    sources=[\"trampoline.cu\"],\n",
    "    extra_ldflags=[\"-lnvrtc\", \"-lcuda\"],\n",
    "    extra_cuda_cflags=[\"-g\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eaaa4d5-7c3c-4929-bbc5-cf1399dfe2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import tempfile\n",
    "import sass_graph\n",
    "\n",
    "def visualize_opal_kernel(kernel, arch=\"sm_75\"):\n",
    "    kernel_builder = kernel_transformer.KernelBuilder()\n",
    "    wmma_test(kernel_builder)\n",
    "    kernel_code = kernel_builder.generate(arch)\n",
    "    \n",
    "    with tempfile.NamedTemporaryFile() as temp_file:\n",
    "        temp_file.write(kernel_code.encode(\"utf-8\"))\n",
    "        subprocess.run([\"ptxas\", \"--gpu-name\", arch, temp_file.name])\n",
    "\n",
    "    cfgs = sass_graph.generate_cfgs(sass_graph.disassemble(\"elf.o\"))\n",
    "    return sass_graph.display_cfg(cfgs[\"wmma_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8fc1d10-760d-450c-a513-d9b823190b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct \n",
    "def float_to_int32(value):\n",
    "    # Pack the float into 4 bytes using IEEE 754 format\n",
    "    packed = struct.pack('f', value)\n",
    "    \n",
    "    # Unpack those bytes as a 32-bit unsigned integer\n",
    "    unpacked = struct.unpack('I', packed)[0]\n",
    "    \n",
    "    return unpacked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "31f7ff35-34b4-4641-aae8-2f1dcb4b469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kernel_transformer.kernel()\n",
    "def simple_wmma_gemm(A: \"u64\", B: \"u64\", D: \"u64\", m: \"u32\", n: \"u32\", k: \"u32\"):\n",
    "    x: u32 = u32(\"%ctaid.x\") * 16\n",
    "    y: u32 = u32(\"%ctaid.y\") * 16\n",
    "\n",
    "    a: b32(8)\n",
    "    b: b32(8)\n",
    "    d: b32(8)\n",
    "\n",
    "    for i in range(8):\n",
    "        ptx.mov.b32(d[i], 0)\n",
    "    \n",
    "    KI: u32 = 0\n",
    "    while KI < k:\n",
    "        _A: u64 = A + (y * k + KI) * 2\n",
    "        _B: u64 = B + (KI * n + x) * 2\n",
    "        \n",
    "        ptx.wmma.load.a.sync.aligned._global.m16n16k16.row.f16({*a}, [_A], k)\n",
    "        ptx.wmma.load.b.sync.aligned._global.m16n16k16.row.f16({*b}, [_B], n)\n",
    "    \n",
    "        ptx.wmma.mma.sync.aligned.m16n16k16.row.row.f32.f32({*d}, {*a}, {*b}, {*d})\n",
    "        KI += 16\n",
    "\n",
    "    _D: u64 = D + (y * n + x) * 4\n",
    "    ptx.wmma.store.d.sync.aligned.m16n16k16._global.row.f32([_D], {*d}, m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b68c7679-5c51-425c-a45d-c6d5112d2ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3228, 0.0168, 0.1490,  ..., 0.5068, 0.2299, 0.5762],\n",
      "        [0.5312, 0.4934, 0.1993,  ..., 0.3250, 0.9209, 0.8271],\n",
      "        [0.6807, 0.9517, 0.7168,  ..., 0.2417, 0.2417, 0.2766],\n",
      "        ...,\n",
      "        [0.2944, 0.0128, 0.0894,  ..., 0.2976, 0.8716, 0.1316],\n",
      "        [0.1379, 0.5337, 0.7734,  ..., 0.1713, 0.2522, 0.0244],\n",
      "        [0.0586, 0.2920, 0.5508,  ..., 0.2754, 0.8848, 0.6543]],\n",
      "       device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "kernel_builder = kernel_transformer.KernelBuilder()\n",
    "simple_wmma_gemm(kernel_builder)\n",
    "kernel_code = kernel_builder.generate()\n",
    "\n",
    "M = 32\n",
    "N = 32\n",
    "K = 32\n",
    "\n",
    "#A = torch.eye(K, dtype=torch.float16, device=\"cuda\")\n",
    "#A = torch.triu(torch.full((K, K), 3, dtype=torch.float16, device=\"cuda\"))\n",
    "A = torch.rand((M, K), dtype=torch.float16, device=\"cuda\")\n",
    "B = torch.eye(K, dtype=torch.float16, device=\"cuda\")\n",
    "\n",
    "D = torch.zeros((M, N), dtype=torch.float32, device=\"cuda\")\n",
    "\n",
    "check = A @ B\n",
    "\n",
    "wrapper = trampoline.CuModuleWrapper()\n",
    "wrapper.load_ptx_code(kernel_code)\n",
    "\n",
    "wrapper.launch_kernel(\"simple_wmma_gemm\", ((M // 16), (N // 16), 1), (32, 1, 1), (A.data_ptr(), B.data_ptr(), D.data_ptr(), M, N, K))\n",
    "\n",
    "print(D)\n",
    "print((D - check).sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
